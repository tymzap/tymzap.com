---
title: Grief, leverage, and the future of manual coding
publishedAt: 2026-01-08
coverImage: lonely-male-figure-walking-in-blizzard.webp
---

For the last couple of years, watching the software industry has been an emotional experience for me. I will remember the winter of 2025/2026 - the time when apparently everyone and your mum discovered just how good in coding the Claude Opus 4.5 is - as the culmination of that period, and one of the hardest and most confusing times for me as a professional.

On one hand, there's anxiety. The pace of change is brutal. New tools appear every week, workflows become obsolete almost overnight. It's unclear which parts of the job are still durable enough to survive more than a few years.

I felt strange hearing from industry thought leaders like Andrej Karpathy, saying that [English is now the new programming language](https://x.com/karpathy/status/1617979122625712128). I had spent years honing the craft of writing in programming languages - so what was I supposed to make of that, if it was now commoditized?

After months of thinking about that, I had identified the feeling - grief. Grief for manual coding.

For years, my identity as an engineer was tightly coupled to the *artifacts* I produced. My repositories. My components. My abstractions. The code was mine, and that ownership mattered. It was craft and it was personal. Like a carpenter remembering how it felt to build a specific chair.

That mental model no longer holds for me. How could it, when everyone now can one-shot a todo app for themselves, just like a PowerPoint presentation? 

## Leverage

On the other hand, there's excitement. I got into coding because I wanted to **create worlds**. Websites, apps, flows, solutions, interactions between users, beautiful and unique things.

Now the ceiling of building is so high that we cannot even see it. Ideas that felt too expensive or too complex are suddenly within reach. It's not an understatement to say things that used to take weeks and months now may take hours. I'm not saying that it's easy to do it and everyone can make it happen, but it's certainly *possible*. 

The new leverage comes from moving one layer up. Instead of doing every task ourselves, we design systems that can do them for us. A single agent can now execute autonomously what used to require long hours my time, freeing my attention for higher-level decisions, design, judgment. And maybe just... enjoying the life with my loved ones?

This all immensely increases the leverage of single engineer. Technically, you're one well designed system away from solving a daunting problem for the first time, from building life-changing startup, from building your dream game. Of course, it's still hard and rare, but with pre-agentic coding it was often not possible at all - you had to broke the concrete walls of thousands of lines of code first.

I mentioned that everyone with AI can one-shot a personal to-do app now. Engineers with AI can create much more that. They can design systems that scale, adapt, and solve problems in ways that were previously out of reach, everything under strict engineering discipline - secure, cheap and efficient.

That's why, overall, I am cautiously optimistic on what the future holds.

And it seems like - as buzzwordy and clichÃ© as it sounds - that the future is agentic.

## What an agentic system actually is

The word *agentic* gets thrown around a lot, so it's worth grounding it. From my experience, it comes down to five core steps:

1. Decide what should exist. Define intent, constraints, and goals before anything runs.
2. Implement the system. Create the process that will produce outputs - subagents, tools, prompts, input and output schemas.
3. Let agents execute. Delegate actual production to models operating inside that system.
4. Verify the output. Judge correctness, quality, and alignment with your goals. Decide what survives.
5. Iterate. Refine the system based on what it produces.

Points 2, 4 ad 5 can be somewhat "recursively" executed by agents - it's not hard to imagine agents implementing the system by writing specs or veryfing the outputs for other agents.

Points 1 and 3 are uniquely human - we decide what we want to exist, and we trigger the execution process. And while point 3 - triggering the execution - also can be run by agent, I keep it in this category because someone is at the end is *responsible* for what the agents did, and in that sense it is uniquely human. 

## Engineers, but different

This shift doesn't mean the broad engineering skill is obsolete. It means *where* that skill applies has changed.

To orchestrate agents that produce valid code, I still need to understand:
- System design
- Performance trade-offs
- UX

And what is even more important:
- Product constraints
- Business requirements
- Taste
  
Rather than coding all of that manually, I embed the intent into the generative system, which produces output nondeterministically - and on much broader scale. We don't know yet which scale we talk about. 2x? 10x? Maybe more? We will see.

And there's whole new class of problem to solve. How do I ensure models doesn't produce unexpected or harmful results? How do I coordinate several, dozen, and more models to work together? How do I ensure AI runs on prem and we don't share our precious data with anyone? 

In other words, the craft moves up a level.

## The bottom line
Initially, I wanted to include "the **end** of manual coding" in this post's  title. But I changed it to "the **future** manual of coding".

First, I didn't want to sound clickbaity. Now, seriously - manual coding isn't gone. It still has a very important place. Best professionals always understood different abstraction levels, not only the highest one. Code is runtime, and you have to understand runtime through and through. Apart from that - it's still important in learning, personal work, and honing the cognitive skills. I especially believe in the last one, because offloading so much mental work may affect how we think in the long term.

But it's no longer the default path to producing value and to economic leverage. The role of software engineers is shifting:

> We no longer **produce artifacts** (code). We **design systems that produce artifacts**.

Once you accept that, a lot of confusion from the last couple of years disappears. The grief is still there, but it's quieter. And there is something else: the clarity, and a sense that this change, while uncomfortable, is also full of possibility.

One important note: no, all of this doesn't mean succumbing to AI slop. We're still responsible for everything our agents produce - every single line of it. And no, it doesn't mean letting AI write sloppy LinkedIn posts or Slack messages is suddenly acceptable. If anything, the opposite: write your damn words yourself, please. Do not delegate your thinking.

## The future
There's a whole lot of skill to designing the agentic systems including mastering specs engineering, enforcing constraints, output verification, model evaluation and so on. This is the obvious thing to focus on first. 

Many people dreamed of living in times with real blank spots on the map, to be able to discover the unknown themselves. Software engineers in 2026 have the privilege of experiencing this. And it can be a source of risk, as well as an economic leverage.

We've always been good at automating and learning new things. Now there's even more to automate and learn. Our focus should **shift from manual coding to designing systems that produce code at scale** - while remembering that manual coding got us here, and still matters, just for different reasons.